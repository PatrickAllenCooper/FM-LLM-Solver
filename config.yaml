env_vars:
  MATHPIX_APP_ID: ''
  MATHPIX_APP_KEY: ''
  UNPAYWALL_EMAIL: ''
  SEMANTIC_SCHOLAR_API_KEY: ''
huggingface:
  use_auth: false
  local_model_path: ''
paths:
  project_root: .
  data_dir: data
  output_dir: output
  pdf_input_dir: ${paths.data_dir}/fetched_papers
  user_ids_csv: ${paths.data_dir}/user_ids.csv
  eval_benchmark_file: ${paths.data_dir}/benchmark_systems.json
  # Knowledge base paths (unified by default)
  kb_output_dir: kb_data
  kb_vector_store_filename: paper_index_mathpix.faiss
  kb_metadata_filename: paper_metadata_mathpix.jsonl
  # Discrete barrier certificate knowledge base paths
  kb_discrete_output_dir: kb_data_discrete
  kb_discrete_vector_store_filename: paper_index_discrete.faiss
  kb_discrete_metadata_filename: paper_metadata_discrete.jsonl
  # Continuous barrier certificate knowledge base paths
  kb_continuous_output_dir: kb_data_continuous
  kb_continuous_vector_store_filename: paper_index_continuous.faiss
  kb_continuous_metadata_filename: paper_metadata_continuous.jsonl
  # Fine-tuning data paths
  ft_manual_data_file: ${paths.data_dir}/ft_manual_data.jsonl
  ft_extracted_data_file: ${paths.data_dir}/ft_extracted_data_verified.jsonl
  ft_combined_data_file: ${paths.data_dir}/ft_data_combined.jsonl
  # Type-specific fine-tuning data paths
  ft_discrete_data_file: ${paths.data_dir}/ft_data_discrete.jsonl
  ft_continuous_data_file: ${paths.data_dir}/ft_data_continuous.jsonl
  ft_output_dir: ${paths.output_dir}/finetuning_results
  eval_results_file: ${paths.output_dir}/evaluation_results.csv
data_fetching:
  sleep_time_scholarly: 3
  sleep_time_api: 1.5
  sleep_time_retry: 5
  max_retries: 2
  requests_user_agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
    (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36
  publication_limit_per_author: 50
knowledge_base:
  embedding_model_name: all-mpnet-base-v2
  chunk_target_size_mmd: 1000
  chunk_overlap_mmd: 150
  mathpix_poll_max_wait_sec: 600
  mathpix_poll_interval: 10
  pipeline: "open_source"  # Pipeline for PDF processing: 'mathpix' or 'open_source'
  gpu_memory_limit: 3072   # Max VRAM to use in MB (reduced for RTX 3080)
  embedding_batch_size: 16  # Reduced batch size for embedding generation
  low_memory_mode: true    # Enabled memory optimizations
  # Barrier certificate type-specific configurations
  barrier_certificate_type: "discrete"  # Options: "unified", "discrete", "continuous"
  # Classification settings for automatic document categorization
  classification:
    enable_auto_classification: true  # Automatically classify documents
    discrete_keywords: ["discrete", "hybrid automata", "symbolic", "finite state", "temporal logic", "LTL", "CTL", "model checking", "transition system", "discrete dynamics"]
    continuous_keywords: ["continuous", "differential equation", "control theory", "Lyapunov", "SOS", "polynomial", "semidefinite", "continuous dynamics", "flow", "vector field"]
    confidence_threshold: 0.6  # Minimum confidence for classification (0.0-1.0)

# Added embeddings section to match the structure expected by the code
embeddings:
  model_name: all-mpnet-base-v2
  chunk_size: 1000
  chunk_overlap: 150
  batch_size: 16           # Reduced batch size for embedding generation

fine_tuning:
  base_model_name: "Qwen/Qwen2.5-14B-Instruct"
  data_format: instruction
  use_adapter: true
  # Barrier certificate type for fine-tuning (should match knowledge_base.barrier_certificate_type)
  barrier_certificate_type: "discrete"  # Options: "unified", "discrete", "continuous"
  lora:
    r: 8                  # Reduced from 16 to 8 for memory savings
    alpha: 8              # Reduced from 16 to 8 for memory savings
    dropout: 0.1
    target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
  quantization:
    use_4bit: true
    bnb_4bit_compute_dtype: float16
    bnb_4bit_quant_type: nf4
    use_nested_quant: true  # Enabled for additional memory savings
  training:
    num_train_epochs: 1
    per_device_train_batch_size: 1      # Keep at 1
    per_device_eval_batch_size: 1       # Reduced from 4 to 1
    gradient_accumulation_steps: 8      # Increased from 4 to 8
    gradient_checkpointing: true
    max_grad_norm: 0.3
    learning_rate: 0.0002
    weight_decay: 0.001
    optim: paged_adamw_32bit
    lr_scheduler_type: cosine
    max_steps: -1
    warmup_ratio: 0.03
    group_by_length: false    # Disabled as it can use more memory
    save_steps: 50            # Save less frequently to reduce I/O overhead
    logging_steps: 10
    packing: false
    max_seq_length: 1024      # Set a fixed sequence length to optimize memory usage
inference:
  rag_k: 3
  max_new_tokens: 200           # Reduced from 512 - certificates are short expressions
  temperature: 0.3              # Lowered from 0.6 for more focused output
  top_p: 0.85                   # Slightly reduced from 0.9 for better quality
  device: "auto"  # Use GPU if available, fallback to CPU
  torch_dtype: "auto"  # Automatic precision selection
  # Stop tokens to prevent incomplete generation
  stop_sequences: ["Therefore", "However", "But", "Let", "We can", "Note that"]
  # Better sampling parameters for mathematical expressions
  do_sample: true
  repetition_penalty: 1.1       # Prevent repetitive text
  pad_token_id: null            # Will be set by tokenizer
evaluation:
  rag_k: ${inference.rag_k}
  max_new_tokens: ${inference.max_new_tokens}
  temperature: ${inference.temperature}
  top_p: ${inference.top_p}
  verification:
    num_samples_lie: 5000       # Reduced from 10000 for faster verification
    num_samples_boundary: 3000  # Reduced from 5000 for faster verification
    numerical_tolerance: 1.0e-06
    sos_default_degree: 2
    sos_epsilon: 1.0e-07
    optimization_max_iter: 75   # Reduced from 100 for faster verification
    optimization_pop_size: 10   # Reduced from 15 for faster verification
    attempt_sos: true
    attempt_optimization: true
    # CRITICAL FIX: Set-relative tolerance configuration
    use_set_relative_tolerances: true     # Use bounds from initial set instead of absolute tolerance
    set_tolerance_margin: 0.01            # 1% margin for numerical precision
    absolute_fallback_tolerance: 1.0e-06  # Fallback when no set bound is detected
    # Relaxed domain bounds verification to focus on core barrier conditions
    strict_domain_bounds_check: false     # Allow some domain violations if core conditions hold
    domain_bounds_tolerance: 0.1          # Higher tolerance for domain bounds violations
    # Debug settings
    log_boundary_analysis: true           # Log detailed boundary condition analysis
    save_verification_details: true       # Save detailed verification results

# Database configuration
database:
  primary:
    host: "localhost"
    port: 5432
    database: "fm_llm_solver"
    username: "postgres"
    password: "${secret:DB_PASSWORD}"
    pool_size: 20
    max_overflow: 10
    pool_timeout: 30
    pool_recycle: 3600
    ssl_mode: "prefer"
    echo: false
  # Optional secondary database for read replicas
  replica:
    host: "localhost"
    port: 5432
    database: "fm_llm_solver_replica"
    username: "postgres"
    password: "${secret:DB_PASSWORD}"
    pool_size: 10
    max_overflow: 5
    pool_timeout: 30
    pool_recycle: 3600
    ssl_mode: "prefer"
    echo: false

# Logging configuration
logging:
  log_directory: "logs"
  root_level: "INFO"
  loggers:
    api:
      level: "INFO"
      handlers: ["console", "rotating_file"]
      json_format: true
      propagate: false
    model_operations:
      level: "INFO"
      handlers: ["console", "rotating_file"]
      json_format: true
      propagate: false
    security:
      level: "WARNING"
      handlers: ["console", "rotating_file", "syslog"]
      json_format: true
      propagate: false
    performance:
      level: "INFO"
      handlers: ["rotating_file"]
      json_format: true
      propagate: false
    database:
      level: "INFO"
      handlers: ["console", "rotating_file"]
      json_format: true
      propagate: false
    web:
      level: "INFO"
      handlers: ["console", "rotating_file"]
      json_format: true
      propagate: false

# Cache configuration
cache:
  backend: "memory"  # Options: "memory", "redis", "hybrid"
  max_size: 1000
  default_ttl: 3600  # 1 hour in seconds
  redis_url: null  # Set to Redis URL if using Redis backend
  redis_db: 0
  redis_max_connections: 20
  key_prefix: "fm_llm:"
  namespace: "default"

# Web interface configuration
web_interface:
  host: "127.0.0.1"
  port: 5000
  debug: true
  database_path: "web_interface/instance/app.db"
  # Security settings
  secret_key_env: "SECRET_KEY"  # Environment variable name for secret key
  # CORS settings for API access
  cors_origins: ["http://localhost:3000", "http://127.0.0.1:3000"]  # Add frontend origins if needed
