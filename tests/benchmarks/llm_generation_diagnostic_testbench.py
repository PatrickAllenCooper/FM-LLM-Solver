#!/usr/bin/env python3
"""
LLM Generation Diagnostic Testbench
===================================

This testbench diagnoses and fixes the specific LLM generation issues:
- Incomplete responses ("Therefore, we'll opt")
- Placeholder variables (Œ±, Œ≤, C)
- Poor certificate extraction
- Overly complex prompts

Run with: python tests/llm_generation_diagnostic_testbench.py
"""

import json
import logging
import os
import sys
import threading
import time

# Add project root to path
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, PROJECT_ROOT)

from inference.generate_certificate import format_prompt_with_context
from utils.config_loader import load_config
from web_interface.certificate_generator import CertificateGenerator

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class LLMGenerationDiagnosticTestbench:
    """Diagnostic testbench for LLM generation issues"""

    def __init__(self):
        self.config = load_config()
        self.certificate_generator = None
        self.generation_in_progress = False

        logger.info("üîß Initializing Certificate Generator...")
        try:
            self.certificate_generator = CertificateGenerator(self.config)
            logger.info("‚úÖ Certificate generator initialized successfully")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize certificate generator: {e}")

    def diagnose_current_system(self):
        """Diagnose the current system with the user's problematic case"""
        logger.info("üîç DIAGNOSING CURRENT SYSTEM")
        logger.info("=" * 50)

        # Test case from user
        system_desc = "System Dynamics: dx/dt = -x, dy/dt = -y\nInitial Set: x**2 + y**2 <= 0.25\nUnsafe Set: x**2 + y**2 >= 4.0"
        domain_bounds = {"x": [-3, 3], "y": [-3, 3]}

        logger.info(f"üìã Test case: {system_desc}")
        logger.info(f"üéØ Domain bounds: {domain_bounds}")

        if self.certificate_generator:
            try:
                logger.info("üöÄ Starting LLM generation...")
                logger.info("‚è≥ This may take 30-60 seconds with the 14B model...")

                # Show progress during generation
                self.generation_in_progress = True
                progress_thread = threading.Thread(target=self._show_progress)
                progress_thread.daemon = True
                progress_thread.start()

                start_time = time.time()
                result = self.certificate_generator.generate_certificate(
                    system_desc, "base", rag_k=0, domain_bounds=domain_bounds
                )

                self.generation_in_progress = False
                generation_time = time.time() - start_time

                logger.info(f"‚úÖ Generation completed in {generation_time:.1f} seconds")
                self._analyze_result(result)
                return result

            except Exception as e:
                self.generation_in_progress = False
                logger.error(f"‚ùå Generation failed: {e}")
                return None
        else:
            logger.warning("‚ö†Ô∏è  No certificate generator - using mock analysis")
            # Mock the problematic output from user
            mock_result = {
                "success": True,
                "llm_output": "B(x, y) = x + Œ±y - C, but this could fail if x becomes negative. Therefore, we'll opt",
                "certificate": None,
                "prompt_length": 3500,
            }
            self._analyze_result(mock_result)
            return mock_result

    def _show_progress(self):
        """Show progress indicators during generation"""
        dots = 0
        while self.generation_in_progress:
            time.sleep(2)
            if self.generation_in_progress:
                dots = (dots + 1) % 4
                progress_str = "üîÑ Generating" + "." * dots + " " * (3 - dots)
                print(f"\r{progress_str}", end="", flush=True)
        print()  # New line when done

    def _analyze_result(self, result):
        """Analyze the generation result for issues"""
        logger.info("\nüîç DETAILED ANALYSIS RESULTS:")
        logger.info("-" * 40)

        llm_output = result.get("llm_output", "")
        certificate = result.get("certificate", "")
        prompt_length = result.get("prompt_length", 0)

        logger.info(f"üìù LLM Output Length: {len(llm_output)} characters")
        logger.info(
            f"üìù LLM Output Preview: {llm_output[:200]}{'...' if len(llm_output) > 200 else ''}"
        )
        logger.info(f"üîß Extracted Certificate: {certificate}")
        logger.info(f"üìè Prompt Length: {prompt_length} characters")

        # Issue Analysis
        issues_found = []

        # Issue 1: Placeholder variables
        if self._has_placeholders(llm_output):
            issues_found.append("PLACEHOLDERS")
            logger.warning("‚ö†Ô∏è  ISSUE 1: Contains placeholder variables (Œ±, Œ≤, C)")
            placeholders = self._find_placeholders(llm_output)
            logger.warning(f"   Found placeholders: {placeholders}")

        # Issue 2: Incomplete generation
        if self._is_incomplete(llm_output):
            issues_found.append("INCOMPLETE")
            logger.warning("‚ö†Ô∏è  ISSUE 2: Generation is incomplete")
            incomplete_indicators = self._find_incomplete_indicators(llm_output)
            logger.warning(f"   Incomplete indicators: {incomplete_indicators}")

        # Issue 3: Extraction failure
        if not certificate:
            issues_found.append("EXTRACTION_FAILED")
            logger.warning("‚ö†Ô∏è  ISSUE 3: Certificate extraction failed")

        # Issue 4: Prompt too long
        if prompt_length > 2500:
            issues_found.append("PROMPT_TOO_LONG")
            logger.warning(f"‚ö†Ô∏è  ISSUE 4: Prompt is too long ({prompt_length} chars)")

        if not issues_found:
            logger.info("‚úÖ No major issues detected!")
        else:
            logger.warning(f"‚ö†Ô∏è  Issues found: {', '.join(issues_found)}")

        return issues_found

    def _has_placeholders(self, text):
        """Check for placeholder variables"""
        placeholders = ["Œ±", "Œ≤", "Œ≥", "C", "\\alpha", "\\beta"]
        return any(p in text for p in placeholders)

    def _find_placeholders(self, text):
        """Find specific placeholders in text"""
        placeholders = ["Œ±", "Œ≤", "Œ≥", "C", "\\alpha", "\\beta"]
        found = [p for p in placeholders if p in text]
        return found

    def _is_incomplete(self, text):
        """Check for incomplete generation"""
        incomplete_patterns = [
            "Therefore, we'll opt",
            "but this could fail",
            "we need to consider",
            "However, we",
        ]
        return any(p in text for p in incomplete_patterns)

    def _find_incomplete_indicators(self, text):
        """Find specific incomplete indicators"""
        incomplete_patterns = [
            "Therefore, we'll opt",
            "but this could fail",
            "we need to consider",
            "However, we",
        ]
        found = [p for p in incomplete_patterns if p in text]
        return found

    def test_improved_prompts(self):
        """Test improved prompting strategies"""
        logger.info("\nüß™ TESTING IMPROVED PROMPTS")
        logger.info("=" * 50)

        system_desc = "System Dynamics: dx/dt = -x, dy/dt = -y\nInitial Set: x**2 + y**2 <= 0.25\nUnsafe Set: x**2 + y**2 >= 4.0"
        domain_bounds = {"x": [-3, 3], "y": [-3, 3]}

        # Current prompt (problematic)
        logger.info("üìä Analyzing current prompt structure...")
        current_prompt = format_prompt_with_context(
            system_desc, "", "unified", domain_bounds
        )
        logger.info(f"üìè Current prompt length: {len(current_prompt)} chars")

        # Count specific elements in current prompt
        instruction_count = current_prompt.count("IMPORTANT:")
        example_count = current_prompt.count("Example")
        warning_count = current_prompt.count("‚ö†Ô∏è")

        logger.info("üìä Current prompt analysis:")
        logger.info(f"   - Instructions: {instruction_count}")
        logger.info(f"   - Examples: {example_count}")
        logger.info(f"   - Warnings: {warning_count}")

        # Generate improved prompts
        logger.info("\nüîß Generating improved prompt alternatives...")
        improved_prompts = {
            "minimal": self._create_minimal_prompt(system_desc, domain_bounds),
            "direct": self._create_direct_prompt(system_desc, domain_bounds),
            "constrained": self._create_constrained_prompt(system_desc, domain_bounds),
        }

        for name, prompt in improved_prompts.items():
            logger.info(
                f"üìè {name.capitalize()} prompt: {len(prompt)} chars ({len(current_prompt) - len(prompt):+d} vs current)"
            )
            logger.info(f"   Preview: {prompt[:100]}...")

        return improved_prompts

    def _create_minimal_prompt(self, system_desc, domain_bounds):
        """Minimal prompt - just the essentials"""
        domain_text = ""
        if domain_bounds:
            domain_desc = ", ".join(
                [
                    f"{var} ‚àà [{bounds[0]}, {bounds[1]}]"
                    for var, bounds in domain_bounds.items()
                ]
            )
            domain_text = f"Domain: {domain_desc}\n"

        return """<s>[INST] Generate a barrier certificate:

{system_desc}
{domain_text}
Use concrete numbers only (no Œ±, Œ≤, C). Format: B(x, y) = <expression>

BARRIER_CERTIFICATE_START
B(x, y) = [/INST]"""

    def _create_direct_prompt(self, system_desc, domain_bounds):
        """Direct prompt with clear constraints"""
        domain_text = ""
        if domain_bounds:
            domain_desc = ", ".join(
                [
                    f"{var} ‚àà [{bounds[0]}, {bounds[1]}]"
                    for var, bounds in domain_bounds.items()
                ]
            )
            domain_text = f"Domain: {domain_desc}\n"

        return """<s>[INST] Generate a barrier certificate for:

{system_desc}
{domain_text}
CRITICAL: Use only real numbers (1.0, -2.5, 3.14). No variables like Œ±, Œ≤, C.
Complete the expression fully.

Examples:
- B(x, y) = x**2 + y**2 - 1.0
- B(x, y) = 2*x**2 + 0.5*y**2 - 3.0

BARRIER_CERTIFICATE_START
B(x, y) = [/INST]"""

    def _create_constrained_prompt(self, system_desc, domain_bounds):
        """Constrained prompt that forces completion"""
        domain_text = ""
        if domain_bounds:
            domain_desc = ", ".join(
                [
                    f"{var} ‚àà [{bounds[0]}, {bounds[1]}]"
                    for var, bounds in domain_bounds.items()
                ]
            )
            domain_text = f"Domain: {domain_desc}\n"

        return """<s>[INST] Complete the barrier certificate:

{system_desc}
{domain_text}
BARRIER_CERTIFICATE_START
B(x, y) = x**2 + y**2 - [/INST]"""

    def suggest_fixes(self):
        """Suggest specific fixes for the identified issues"""
        logger.info("\nüí° SPECIFIC FIXES TO IMPLEMENT")
        logger.info("=" * 50)

        logger.info("1. üìù PROMPT OPTIMIZATION:")
        logger.info("   ‚úì Replace current 3500+ char prompt with 500-800 char version")
        logger.info("   ‚úì Remove verbose discrete-time warnings and examples")
        logger.info("   ‚úì Focus on essential constraint: 'Use concrete numbers only'")

        logger.info("\n2. üîß EXTRACTION IMPROVEMENTS:")
        logger.info("   ‚úì Add fallback regex for incomplete expressions")
        logger.info("   ‚úì Handle partial mathematical expressions")
        logger.info("   ‚úì Detect and reject placeholder variables")

        logger.info("\n3. ‚öôÔ∏è  GENERATION PARAMETER TUNING:")
        logger.info("   ‚úì Increase max_new_tokens from current to 200+")
        logger.info("   ‚úì Lower temperature to 0.3 for more focused output")
        logger.info("   ‚úì Add stop tokens: ['Therefore', 'However', 'But']")

        logger.info("\n4. üéØ IMMEDIATE IMPLEMENTATION:")
        logger.info("   ‚úì Update format_prompt_with_context() function")
        logger.info("   ‚úì Enhance extract_certificate_from_output() method")
        logger.info("   ‚úì Add placeholder detection and rejection")


def main():
    """Main execution with verbose progress reporting"""
    logger.info("üéØ LLM Generation Diagnostic Testbench")
    logger.info("=====================================")
    logger.info("‚è≥ This will take 2-3 minutes with the 14B model")
    logger.info("üîç Analyzing current system behavior...")

    testbench = LLMGenerationDiagnosticTestbench()

    # Run diagnostics with progress reporting
    logger.info("\nüî¨ Phase 1: Current System Diagnosis")
    result = testbench.diagnose_current_system()

    logger.info("\nüî¨ Phase 2: Prompt Analysis")
    improved_prompts = testbench.test_improved_prompts()

    logger.info("\nüî¨ Phase 3: Fix Recommendations")
    testbench.suggest_fixes()

    # Save results
    logger.info("\nüíæ Saving diagnostic results...")
    results = {
        "current_result": result,
        "improved_prompts": {k: v for k, v in improved_prompts.items()},
        "timestamp": time.time(),
    }

    with open("llm_generation_diagnostics.json", "w") as f:
        json.dump(results, f, indent=2)

    logger.info(
        "‚úÖ Diagnosis complete! Results saved to llm_generation_diagnostics.json"
    )
    logger.info("üöÄ Ready to implement fixes to the certificate generation system")
    logger.info("\nüìä SUMMARY:")
    if result:
        logger.info(f"   - Generation successful: {result.get('success', False)}")
        logger.info(f"   - Certificate extracted: {bool(result.get('certificate'))}")
        logger.info(f"   - Output length: {len(result.get('llm_output', ''))}")
    logger.info("   - Improved prompts generated: 3 variants")
    logger.info("   - Fix recommendations: 4 categories")


if __name__ == "__main__":
    main()
