# Simplified Dockerfile for FM-LLM Solver
# Focused on real LLM GPU testing pipeline

FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# Environment setup
ENV PYTHONUNBUFFERED=1 \
    DEBIAN_FRONTEND=noninteractive \
    CUDA_VISIBLE_DEVICES=0 \
    PYTHONPATH=/app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3-pip \
    git \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements
COPY requirements.txt ./
RUN pip3 install --no-cache-dir -r requirements.txt

# Install PyTorch with CUDA support
RUN pip3 install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Copy application code
COPY . .

# Create directories
RUN mkdir -p logs test_results

# Expose port for web interface
EXPOSE 5000

# Default command
CMD ["python3", "run_web_interface.py"] 