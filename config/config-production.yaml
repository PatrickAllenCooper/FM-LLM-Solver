# FM-LLM Solver Production Configuration
# Extends the main config.yaml with production-specific overrides
# Usage: Load config.yaml first, then merge these overrides

# ============================================================================
# Environment & System (Production Overrides)
# ============================================================================
environment:
  mode: production
  debug: false
  log_level: INFO

# ============================================================================
# Database (Production PostgreSQL)
# ============================================================================
database:
  url: ${ENV:DATABASE_URL:postgresql://fmllm:${ENV:DB_PASSWORD}@127.0.0.1:5432/fm_llm_solver}
  pool_size: 20
  max_overflow: 40
  pool_timeout: 60
  pool_recycle: 3600
  echo: false

# ============================================================================
# Cache (Production Redis)
# ============================================================================
cache:
  enabled: true
  url: ${ENV:REDIS_URL:redis://10.66.171.51:6379/0}
  default_timeout: 7200
  key_prefix: "fmllm:prod:"

# ============================================================================
# Web Interface (Production)
# ============================================================================
web:
  host: "0.0.0.0"
  port: 5000
  
  # Enhanced security for production
  csrf_enabled: true
  session_timeout: 1800  # 30 minutes
  max_content_length: 52428800  # 50MB
  
  # User management in production
  enable_registration: false  # Disable public registration
  enable_api_keys: true
  default_subscription: basic
  
  # Stricter rate limiting for production
  rate_limit:
    enabled: true
    default: "50 per hour"
    api: "500 per hour"
    burst: "5 per minute"
  
  # User quotas (enforced in production)
  quotas:
    free:
      daily_limit: 50
      monthly_limit: 500
    premium:
      daily_limit: 200
      monthly_limit: 2000
    enterprise:
      daily_limit: 1000
      monthly_limit: 10000

# ============================================================================
# Inference (Production)
# ============================================================================
inference:
  host: "0.0.0.0"
  port: 8000
  timeout: 600  # Longer timeout for production
  
  # Production model configurations
models:
  base:
      name: "Qwen/Qwen2.5-14B-Instruct"
    barrier_type: "discrete"
      max_new_tokens: 512
      temperature: 0.05  # More deterministic in production
      top_p: 0.9
      device_map: auto
      torch_dtype: bfloat16
      load_in_4bit: true  # Memory optimization

# ============================================================================
# Performance (Production Optimized)
# ============================================================================
performance:
  cuda:
    visible_devices: "0"
    memory_config: "max_split_size_mb:1024"
  
  cpu_workers: 8
  max_memory: 32
  
  model_cache_size: 1  # Conservative memory usage
  enable_model_offload: true

# ============================================================================
# Deployment (Cloud/GCP)
# ============================================================================
deployment:
  mode: cloud
  
  services:
    web:
      enabled: true
      workers: 8
      timeout: 300
    
    inference:
      enabled: true
      workers: 2
      timeout: 600
      
    database:
      host: 127.0.0.1  # Cloud SQL proxy
      port: 5432
      
    redis:
      host: 10.66.171.51  # Redis instance IP
      port: 6379
  
  cloud:
    storage_bucket: ${ENV:STORAGE_BUCKET:fm-llm-models}
    cdn_url: ${ENV:CDN_URL:}

# ============================================================================
# Monitoring (Production)
# ============================================================================
monitoring:
  metrics_enabled: true
  metrics_port: 9090
  
  health_check_interval: 15  # More frequent checks
  health_check_timeout: 5
  
  track_generation_time: true
  track_memory_usage: true
  track_gpu_usage: true

# ============================================================================
# Security (Production)
# ============================================================================
  security:
  cors_origins: ${ENV:CORS_ORIGINS:https://fmgen.net,https://fm-llm-solver.fmgen.net}
  csp_enabled: true
  
  api_key_length: 64  # Longer keys for production
  api_rate_limit: "500 per hour"
  
  password_min_length: 12  # Stricter password policy
  password_require_special: true

# ============================================================================
# Feature Flags (Production)
# ============================================================================
features:
  enable_conversation_mode: true
  enable_batch_processing: false  # Disabled for stability
  enable_model_comparison: false  # Disabled to save resources
  enable_verification_service: true
  
  enable_dark_mode: true
  enable_advanced_settings: false  # Simplified UI
  enable_export_formats: ["json", "latex"]  # Limited formats

# ============================================================================
# Logging (Production)
# ============================================================================
logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "/app/logs/fm-llm-solver.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5 