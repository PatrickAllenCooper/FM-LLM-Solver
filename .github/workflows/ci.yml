name: FM-LLM-Solver CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.10'
  NODE_VERSION: '18'

jobs:
  # ============= CODE QUALITY CHECKS =============
  code-quality:
    runs-on: ubuntu-latest
    name: Code Quality & Linting
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache Python Dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8 black isort mypy pylint bandit safety
        pip install -r requirements.txt
    
    - name: Run Black Code Formatter Check
      run: |
        black --check --diff --color .
      continue-on-error: false
    
    - name: Run isort Import Sorting Check
      run: |
        isort --check-only --diff --color .
      continue-on-error: false
    
    - name: Run Flake8 Linting
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Run Pylint Analysis
      run: |
        pylint --fail-under=7.0 fm_llm_solver/ web_interface/ || echo "Pylint score below threshold"
      continue-on-error: true
    
    - name: Run Security Analysis with Bandit
      run: |
        bandit -r . -f json -o bandit-report.json || true
        bandit -r . --severity-level medium
      continue-on-error: true
    
    - name: Check Dependencies for Security Vulnerabilities
      run: |
        safety check --json --output safety-report.json || true
        safety check
      continue-on-error: true
    
    - name: Upload Security Reports
      uses: actions/upload-artifact@v3
      with:
        name: security-reports
        path: |
          bandit-report.json
          safety-report.json
      if: always()

  # ============= UNIT AND INTEGRATION TESTS =============
  tests:
    runs-on: ubuntu-latest
    name: Unit & Integration Tests
    needs: code-quality
    
    strategy:
      matrix:
        test-suite: [unit, integration, performance]
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache Python Dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-mock pytest-asyncio
        pip install -r requirements.txt
        pip install -r requirements/dev.txt || echo "Dev requirements not found"
    
    - name: Create Test Environment
      run: |
        mkdir -p instance
        mkdir -p logs
        mkdir -p test_results
        export DATABASE_URL="sqlite:///instance/test.db"
        export SECRET_KEY="test-secret-key"
        export TESTING=true
    
    - name: Run Unit Tests
      if: matrix.test-suite == 'unit'
      run: |
        pytest tests/unit/ -v --cov=fm_llm_solver --cov=web_interface \
          --cov-report=xml --cov-report=html --cov-report=term \
          --junitxml=test_results/unit-test-results.xml
    
    - name: Run Integration Tests
      if: matrix.test-suite == 'integration'
      run: |
        pytest tests/integration/ -v --timeout=300 \
          --junitxml=test_results/integration-test-results.xml
    
    - name: Run Performance Tests
      if: matrix.test-suite == 'performance'
      run: |
        pytest tests/performance/ -v --timeout=600 \
          --junitxml=test_results/performance-test-results.xml
      continue-on-error: true
    
    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      with:
        name: test-results-${{ matrix.test-suite }}
        path: |
          test_results/
          htmlcov/
      if: always()
    
    - name: Upload Coverage to Codecov
      if: matrix.test-suite == 'unit'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  # ============= DOCKER BUILD AND SECURITY SCAN =============
  docker-build:
    runs-on: ubuntu-latest
    name: Docker Build & Security Scan
    needs: [code-quality, tests]
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: Build Docker Images
      run: |
        # Build web interface
        docker build -f deployment/docker/Dockerfile.web -t fm-llm-web:test .
        
        # Build inference service
        docker build -f deployment/docker/Dockerfile.inference -t fm-llm-inference:test .
    
    - name: Run Docker Security Scan
      run: |
        # Install Trivy for security scanning
        sudo apt-get update
        sudo apt-get install wget apt-transport-https gnupg lsb-release
        wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
        echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
        sudo apt-get update
        sudo apt-get install trivy
        
        # Scan images
        trivy image --format json --output docker-security-web.json fm-llm-web:test || true
        trivy image --format json --output docker-security-inference.json fm-llm-inference:test || true
        
        # Display critical and high severity issues
        trivy image --severity HIGH,CRITICAL fm-llm-web:test
        trivy image --severity HIGH,CRITICAL fm-llm-inference:test
      continue-on-error: true
    
    - name: Upload Docker Security Reports
      uses: actions/upload-artifact@v3
      with:
        name: docker-security-reports
        path: |
          docker-security-*.json
      if: always()

  # ============= DEPLOYMENT VALIDATION =============
  deployment-validation:
    runs-on: ubuntu-latest
    name: Deployment Validation
    needs: [code-quality, tests, docker-build]
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install docker-compose
    
    - name: Validate Configuration Files
      run: |
        echo "Validating YAML configuration files..."
        python -c "
        import yaml
        import os
        import sys
        
        config_files = [
            'config.yaml',
            'config/base.yaml',
            'deployment/kubernetes/fm-llm-full-stack.yaml'
        ]
        
        for config_file in config_files:
            if os.path.exists(config_file):
                try:
                    with open(config_file, 'r') as f:
                        yaml.safe_load(f)
                    print(f'✅ {config_file} is valid')
                except yaml.YAMLError as e:
                    print(f'❌ {config_file} is invalid: {e}')
                    sys.exit(1)
            else:
                print(f'⚠️  {config_file} not found')
        "
    
    - name: Validate Docker Compose Files
      run: |
        echo "Validating Docker Compose files..."
        cd deployment/docker
        docker-compose -f docker-compose.unified.yml config > /dev/null
        echo "✅ Docker Compose files are valid"
    
    - name: Test Local Deployment
      run: |
        echo "Testing local deployment..."
        cd deployment/docker
        docker-compose -f docker-compose.unified.yml up -d --build
        sleep 30
        
        # Test health endpoints
        curl -f http://localhost:5000/api/v1/system/health || echo "Health check failed"
        
        # Cleanup
        docker-compose -f docker-compose.unified.yml down
    
    - name: Validate API Documentation
      run: |
        echo "Validating API documentation..."
        python -c "
        from fm_llm_solver.api.endpoints import create_api
        from flask import Flask
        
        app = Flask(__name__)
        api_bp = create_api()
        app.register_blueprint(api_bp)
        
        with app.app_context():
            print('✅ API endpoints are valid and documented')
        "

  # ============= SECURITY AND COMPLIANCE CHECKS =============
  security-compliance:
    runs-on: ubuntu-latest
    name: Security & Compliance
    needs: [code-quality]
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Run GitLeaks Secret Scanning
      uses: gitleaks/gitleaks-action@v2
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE }}
    
    - name: Check for Sensitive Files
      run: |
        echo "Checking for sensitive files..."
        
        # Files that shouldn't be in repository
        sensitive_patterns=(
          "*.key"
          "*.pem" 
          "*.p12"
          "*.pfx"
          "*password*"
          "*.env"
          "secrets.yaml"
          "credentials.json"
        )
        
        found_sensitive=false
        for pattern in "${sensitive_patterns[@]}"; do
          if find . -name "$pattern" -not -path "./.git/*" | grep -q .; then
            echo "❌ Found sensitive files matching: $pattern"
            find . -name "$pattern" -not -path "./.git/*"
            found_sensitive=true
          fi
        done
        
        if [ "$found_sensitive" = true ]; then
          echo "❌ Sensitive files found in repository"
          exit 1
        else
          echo "✅ No sensitive files found"
        fi
    
    - name: License Compliance Check
      run: |
        echo "Checking license compliance..."
        pip install pip-licenses
        pip-licenses --format=json --output-file=licenses.json
        
        # Check for problematic licenses
        python -c "
        import json
        
        with open('licenses.json', 'r') as f:
            licenses = json.load(f)
        
        problematic_licenses = ['GPL-3.0', 'AGPL-3.0', 'LGPL-3.0']
        issues_found = False
        
        for package in licenses:
            license_name = package.get('License', 'Unknown')
            if any(prob in license_name for prob in problematic_licenses):
                print(f'⚠️  Potentially problematic license: {package[\"Name\"]} ({license_name})')
                issues_found = True
        
        if not issues_found:
            print('✅ No problematic licenses found')
        "
      continue-on-error: true

  # ============= GENERATE REPORT =============
  generate-report:
    runs-on: ubuntu-latest
    name: Generate CI Report
    needs: [code-quality, tests, docker-build, deployment-validation, security-compliance]
    if: always()
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
    
    - name: Download All Artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate CI Report
      run: |
        echo "# FM-LLM-Solver CI/CD Report" > ci-report.md
        echo "" >> ci-report.md
        echo "**Date:** $(date)" >> ci-report.md
        echo "**Commit:** ${{ github.sha }}" >> ci-report.md
        echo "**Branch:** ${{ github.ref_name }}" >> ci-report.md
        echo "" >> ci-report.md
        
        echo "## Job Results" >> ci-report.md
        echo "" >> ci-report.md
        
        # Check job results (simplified)
        echo "- Code Quality: ${{ needs.code-quality.result }}" >> ci-report.md
        echo "- Tests: ${{ needs.tests.result }}" >> ci-report.md  
        echo "- Docker Build: ${{ needs.docker-build.result }}" >> ci-report.md
        echo "- Deployment Validation: ${{ needs.deployment-validation.result }}" >> ci-report.md
        echo "- Security & Compliance: ${{ needs.security-compliance.result }}" >> ci-report.md
        echo "" >> ci-report.md
        
        echo "## Artifacts Generated" >> ci-report.md
        echo "" >> ci-report.md
        if [ -d "test-results-unit" ]; then echo "- Unit test results"; fi >> ci-report.md
        if [ -d "test-results-integration" ]; then echo "- Integration test results"; fi >> ci-report.md
        if [ -d "security-reports" ]; then echo "- Security scan reports"; fi >> ci-report.md
        if [ -d "docker-security-reports" ]; then echo "- Docker security reports"; fi >> ci-report.md
        
        echo "" >> ci-report.md
        echo "## Summary" >> ci-report.md
        echo "" >> ci-report.md
        
        if [ "${{ needs.code-quality.result }}" = "success" ] && [ "${{ needs.tests.result }}" = "success" ]; then
          echo "✅ Build passed all critical checks" >> ci-report.md
        else
          echo "❌ Build failed critical checks" >> ci-report.md
        fi
        
        cat ci-report.md
    
    - name: Upload CI Report
      uses: actions/upload-artifact@v3
      with:
        name: ci-report
        path: ci-report.md 